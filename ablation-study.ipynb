{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SeqMF++: Ablation Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will carry out ablation study experiments in order to investigate impact of low-frequence and high-frequency terms in prediction rule.\n",
    "$$\n",
    "    \\mathbf{r}_u = \\mathbf{Q}\\mathbf{p}_u + \\mathrm{diag}\\Big({\\mathbf{S}_u^{(t)}\\mathbf{Q}\\mathbf{Q}^\\top}\\Big).\n",
    "$$\n",
    "We will stick to the agend presented below in this notebook.\n",
    "\n",
    "0. Load event log (and prepare it is needed).\n",
    "1. Fit model on all available data.\n",
    "2. Split event log to global and local updates (supkey and subkey).\n",
    "3. Define variations for local model and global one.\n",
    "4. Instantiate `Federation` from trained model.\n",
    "5. Define routines for evaluation and monitoring\n",
    "6. Run simulation with prepared federation and a set of routines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "from itertools import product\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import collect_metrics\n",
    "from seqmf_pp import get_conf_mtx_lap_smooth, get_users_sui, least_squares_P, update_Q_partly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedl.seqmf import SeqMFPlusPlus\n",
    "from fedl.simulator import BaseGlobalModel, BaseLocalModel, Federation, simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s %(levelname)s %(message)s',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_session_id(frame: pd.DataFrame, delta: pd.Timedelta):\n",
    "    mask = frame['timestamp'].diff() > delta\n",
    "    session_ids = mask.cumsum()\n",
    "    frame['sid'] = session_ids\n",
    "    return frame\n",
    "\n",
    "\n",
    "def read_flatten_lsapp(path: str = 'data/lsapp.tsv'):\n",
    "    df = pd.read_csv(path, sep='\\t', parse_dates=[2]) \\\n",
    "        .query('event_type == \"Opened\"') \\\n",
    "        .sort_values('timestamp')\n",
    "\n",
    "    df = (\n",
    "        df\n",
    "        .set_index(['user_id', 'timestamp'])\n",
    "        .sort_index()\n",
    "        .reset_index(level=[1])\n",
    "        .groupby(level=[0], group_keys=False)\n",
    "        .apply(assign_session_id, pd.Timedelta('15min'))\n",
    "        .reset_index()\n",
    "        .sort_values('timestamp')\n",
    "    )\n",
    "\n",
    "    counter = defaultdict(lambda: len(counter))\n",
    "    sess_groups = list(\n",
    "        map(counter.__getitem__,\n",
    "            df[['user_id', 'sid']].itertuples(index=False, name=None)))\n",
    "    df.loc[:, 'sess_group'] = sess_groups\n",
    "\n",
    "    user_groups = ((\n",
    "        (df['sess_group'].diff().fillna(0) != 0).cumsum() % 9000\n",
    "    ).diff().fillna(0) < 0).cumsum()\n",
    "    subkey = user_groups.rename('subkey')\n",
    "    df = pd.concat([df, subkey], axis=1)\n",
    "    df['supkey'] = df.subkey // 10\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_flatten_lsapp('data/lsapp.tsv')\n",
    "df['iid'] = df.app_name.factorize(True)[0]\n",
    "df = df.rename(columns={'user_id': 'uid'}) \\\n",
    "    .drop(columns=['session_id', 'app_name', 'event_type', 'sess_group']) \\\n",
    "    .set_index(['supkey', 'subkey', 'uid', 'timestamp']) \\\n",
    "    .sort_index() \\\n",
    "    .reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_period = pd.Timedelta('10d')\n",
    "sub_period = pd.Timedelta('1d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Offline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some statistics from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_items = df.iid.max() + 1\n",
    "n_users = df.uid.max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total', n_items, 'items.')\n",
    "print('Total', n_users, 'users.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are going to train model on all availiable data.\n",
    "This experiment correponds to offline regine when we should get the best base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lap_smooth = 1.0\n",
    "lr = 5e-05\n",
    "n_epochs = 6\n",
    "n_factors = 64\n",
    "n_steps = 4\n",
    "pow_bool = False\n",
    "regularization = 0.1\n",
    "score_gen_mode = 'sum'\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rec = SeqMFPlusPlus(\n",
    "    n_factors=n_factors,\n",
    "    n_items=n_items,\n",
    "    n_users=n_users,\n",
    "    alpha=lap_smooth,\n",
    "    regularization=regularization,\n",
    "    learning_rate=lr,\n",
    "    n_epochs=n_epochs,\n",
    "    n_steps=n_steps,\n",
    "    pow_bool=pow_bool,\n",
    "    random_state=seed,\n",
    ")\n",
    "rec.fit(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Global and Local Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global splits are determined by `supkey` and local (specifically, daily) splits are determined by `subkey`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Local and Global Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalModel(BaseGlobalModel):\n",
    "    \n",
    "    def __init__(self, fed: Federation, alpha, gamma,\n",
    "                 regularization, learning_rate, n_steps, pow_bool):\n",
    "        super().__init__(fed)\n",
    "        self.pow_bool = pow_bool\n",
    "        self.regularization = regularization\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_steps = n_steps\n",
    "\n",
    "    def fit(self, data: pd.DataFrame):\n",
    "        data_plain = data[['uid', 'iid']] \\\n",
    "            .reset_index()\n",
    "        \n",
    "        self.fed.global_factors = update_Q_partly(\n",
    "            Q=self.fed.global_factors,\n",
    "            P=self.fed.local_factors,\n",
    "            data=data_plain,\n",
    "            n_users=self.fed.nousers,\n",
    "            n_items=self.fed.noitems,\n",
    "            user_col='uid',\n",
    "            item_col='iid',\n",
    "            pow_bool=self.pow_bool,\n",
    "            regularization=self.regularization,\n",
    "            lap_smooth=self.alpha,\n",
    "            gamma=self.gamma,\n",
    "            lr=self.learning_rate,\n",
    "            n_steps=self.n_steps,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalModel(BaseLocalModel):\n",
    "\n",
    "    def __init__(self, fed: 'Federation', uid: Any, alpha, gamma,\n",
    "                 regularization, learning_rate, n_steps, pow_bool):\n",
    "        super().__init__(fed, uid)\n",
    "        self.pow_bool = pow_bool\n",
    "        self.regularization = regularization\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_steps = n_steps\n",
    "        \n",
    "    @property\n",
    "    def local_factors(self) -> np.ndarray:\n",
    "        return self.fed.local_factors[self.uid]\n",
    "\n",
    "    def fit(self, data: pd.DataFrame):\n",
    "        data_plain = data \\\n",
    "            .reset_index() \\\n",
    "            [['uid', 'iid']]\n",
    "\n",
    "        Cui, cu = get_conf_mtx_lap_smooth(\n",
    "            data=data_plain,\n",
    "            n_subject=self.fed.nousers,\n",
    "            n_object=self.fed.nousers,\n",
    "            subject_col_name='uid',\n",
    "            object_col_name='iid',\n",
    "            alpha=self.alpha,\n",
    "            gamma=self.gamma,\n",
    "        )\n",
    "\n",
    "        S_dict = get_users_sui(\n",
    "            data=data_plain,\n",
    "            n_items=self.fed.noitems,\n",
    "            user_col='uid',\n",
    "            item_col='iid',\n",
    "            pow_bool=self.pow_bool,\n",
    "            level='uid',\n",
    "        )\n",
    "\n",
    "        # regularizer or move it up.\n",
    "        reg = np.diag(self.regularization * np.ones(self.fed.nofactors))\n",
    "        res = least_squares_P(C=Cui, cu=cu, S_dict=S_dict,\n",
    "                              Q=self.fed.global_factors,\n",
    "                              R=reg, u=self.uid)\n",
    "        \n",
    "        self.fed.local_factors[self.uid] = res\n",
    "\n",
    "    def predict(self, data: pd.DataFrame):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedLocalModel(LocalModel):\n",
    "    \n",
    "    def fit(self, data: pd.DataFrame):\n",
    "        # We just check that update model only on global update.\n",
    "        #\n",
    "        # and adjust local and global update periods.\n",
    "        _, subkey = data.index[0]\n",
    "        subkey = data.subkey.iloc[0]\n",
    "        subtime = (subkey + 1) * sub_period\n",
    "        if subtime % sup_period < sub_period:\n",
    "            super().fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyLocalModel(LocalModel):\n",
    "    \n",
    "    def fit(self, data: pd.DataFrame):\n",
    "        self.fed.local_factors[self.uid] = np.zeros(self.fed.nofactors)\n",
    "    \n",
    "    def predict(self, data: pd.DataFrame):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovianLocalModel(BaseLocalModel):\n",
    "\n",
    "    def fit(self, data: pd.DataFrame):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Instantiate Federation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_federation(rec: SeqMFPlusPlus, data: pd.DataFrame, local_model_ty):\n",
    "    Cui, cu = get_conf_mtx_lap_smooth(\n",
    "        data=data,\n",
    "        n_subject=rec.n_users,\n",
    "        n_object=rec.n_items,\n",
    "        subject_col_name='uid',\n",
    "        object_col_name='iid',\n",
    "        alpha=rec.alpha,\n",
    "        gamma=rec.gamma,\n",
    "    )\n",
    "\n",
    "    # TODO It seems better to use DataFrame instead of dict.\n",
    "    #\n",
    "    # S_dict = pd \\\n",
    "    #     .DataFrame(data=S_dict.items(), columns=['uid', 'S']) \\\n",
    "    #    .set_index(['uid'])\n",
    "    S_dict = get_users_sui(\n",
    "        data=data,\n",
    "        n_items=n_items,\n",
    "        user_col='uid',\n",
    "        item_col='iid',\n",
    "        pow_bool=rec.pow_bool,\n",
    "        level='uid',\n",
    "    )\n",
    "    \n",
    "    if not isinstance(local_model_ty, BaseLocalModel):\n",
    "        for uid in S_dict.keys():\n",
    "            S_dict[uid] = coo_matrix(([], ([], [])), (n_items, n_items)).tocsr()\n",
    "    \n",
    "    global_model_factory = partial(GlobalModel, \n",
    "                                   alpha=rec.alpha,\n",
    "                                   gamma=rec.gamma,\n",
    "                                   regularization=rec.regularization,\n",
    "                                   learning_rate=rec.learning_rate,\n",
    "                                   n_steps=rec.n_steps,\n",
    "                                   pow_bool=rec.pow_bool)\n",
    "    \n",
    "    local_model_factory = partial(local_model_ty,\n",
    "                                  alpha=rec.alpha,\n",
    "                                  gamma=rec.gamma,\n",
    "                                  regularization=rec.regularization,\n",
    "                                  learning_rate=rec.learning_rate,\n",
    "                                  n_steps=rec.n_steps,\n",
    "                                  pow_bool=rec.pow_bool)\n",
    "    \n",
    "    if local_model_ty == DummyLocalModel:\n",
    "        local_factors = np.zeros_like(rec.local_factors)\n",
    "    else:\n",
    "        rng = np.random.RandomState(42)\n",
    "        local_factors = rng.normal(0, 1e-3, rec.local_factors.shape)\n",
    "\n",
    "    return Federation(global_factors=rec.global_factors,\n",
    "                      local_factors=local_factors,\n",
    "                      confidence=cu,\n",
    "                      feedback=Cui,\n",
    "                      transitions=S_dict,\n",
    "                      global_model_factory=global_model_factory,\n",
    "                      local_model_factory=local_model_factory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Evaluation and Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_adjacency(data, n_users, n_items):\n",
    "    \"\"\"Function estimate_adjacency builds adjacency matrix between all users\n",
    "    and all items.\n",
    "    \"\"\"\n",
    "    indices = data[['uid', 'iid']].values.T\n",
    "    values = np.ones(len(data))\n",
    "    counts = coo_matrix((values, indices), (n_users, n_items))\n",
    "    colocs = (counts > 0).astype(np.int32)\n",
    "    return colocs\n",
    "\n",
    "\n",
    "class Evaluator:\n",
    "\n",
    "    def __init__(self, adj, topks=(1, 3, 5)):\n",
    "        self.adj = adj\n",
    "        self.topks = topks\n",
    "        self.reports = []\n",
    "\n",
    "    def __call__(self, keys, frame: pd.DataFrame, fed: Federation):\n",
    "        if (report := self.evaluate(frame, fed)) is None:\n",
    "            return\n",
    "        report['supkey'] = keys[0]\n",
    "        report['subkey'] = keys[1]\n",
    "        report = report \\\n",
    "            .reset_index() \\\n",
    "            .set_index(['supkey', 'subkey', 'metric'])\n",
    "        self.reports.append(report)\n",
    "    \n",
    "    @property\n",
    "    def report(self) -> pd.DataFrame:\n",
    "        return pd.concat(self.reports)\n",
    "        \n",
    "    def evaluate(self, frame: pd.DataFrame, fed: Federation):\n",
    "        # high-frequency (daily) splitting cuts sessions as well.\n",
    "        frame = frame \\\n",
    "            .reset_index() \\\n",
    "            .set_index(['uid', 'sid']) \\\n",
    "            .groupby(level=[0, 1]) \\\n",
    "            .filter(lambda x: len(x) >= 2) \\\n",
    "            .reset_index()\n",
    "        \n",
    "        if frame.empty:\n",
    "            return\n",
    "\n",
    "        # store session as DataFrame of list of lists.\n",
    "        sessions = frame[['uid', 'sid', 'iid']] \\\n",
    "            .reset_index(drop=True) \\\n",
    "            .set_index(['uid', 'sid']) \\\n",
    "            .groupby(level=[0, 1]) \\\n",
    "            .apply(lambda x: list(x.iid)) \\\n",
    "            .groupby(level=[0]) \\\n",
    "            .apply(lambda x: list(x)) \\\n",
    "            .rename('sessions')\n",
    "\n",
    "        # restrictions collect_metrics() has. Namely, all computations should\n",
    "        # be done on a single local model and then lifted to suitable monoid\n",
    "        # like list. However, this implementation does not allow to do so.\n",
    "        def predict(*args, **kwargs):\n",
    "            return self.predict(fed, *args, **kwargs)\n",
    "\n",
    "        metrics, _ = collect_metrics(predict, sessions, self.adj,\n",
    "                                     self.topks, 'known_items')\n",
    "\n",
    "        # Transform dict of dict to list of tuples (k1, k2, v1, v2, ...).\n",
    "        metrics_data = [(k1, k2) + tuple(v2)\n",
    "                        for k1, v1 in metrics.items()\n",
    "                        for k2, v2 in v1.items()]\n",
    "\n",
    "        # Cast list of tuples to DataFrame of metrics and aggregate values.\n",
    "        columns = ('uid', 'metric') + self.topks\n",
    "        records = pd.DataFrame(data=metrics_data, columns=columns)\n",
    "        report = records \\\n",
    "            .set_index(['metric', 'uid']) \\\n",
    "            .groupby(level=[0]) \\\n",
    "            .mean()\n",
    "\n",
    "        return report\n",
    "\n",
    "    def predict(self, fed, uid, sid, sess_items, adj_items):\n",
    "        Q = fed.global_factors\n",
    "        P = fed.local_factors\n",
    "        scores = Q[adj_items] @ (P[uid] + Q[sess_items].sum(axis=0))\n",
    "        return scores\n",
    "    \n",
    "    def reset(self):\n",
    "        self.reports = []\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to manage complexity properly.\n",
    "class MarkovianEvaluator(Evaluator):\n",
    "    \n",
    "    def predict(self, fed, uid, sid, sess_items, adj_items):\n",
    "        mat = fed.transitions[uid]\n",
    "        last = sess_items[-1]\n",
    "        scores = mat[adj_items, last].A[:, 0]\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay = df \\\n",
    "    .set_index(['supkey', 'subkey']) \\\n",
    "    .sort_index()\n",
    "\n",
    "adj = estimate_adjacency(replay, n_users, n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "setups = {\n",
    "    'baseline': LocalModel,\n",
    "    'hypothesis1': FixedLocalModel,\n",
    "    'hypothesis2': DummyLocalModel,\n",
    "}\n",
    "\n",
    "evaluator = Evaluator(adj)\n",
    "evaluator.reset()\n",
    "\n",
    "for name, local_model_ty in setups.items():\n",
    "    evaluator.reset()\n",
    "    fed = make_federation(rec=deepcopy(rec),\n",
    "                          data=df,\n",
    "                          local_model_ty=local_model_ty)\n",
    "    fed = simulate(fed, replay, [evaluator])\n",
    "    reports[name] = evaluator.report.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "setups = {\n",
    "    'item2item': lambda x, y, *args, **kwargs: MarkovianLocalModel(x, y),\n",
    "}\n",
    "\n",
    "evaluator = MarkovianEvaluator(adj)\n",
    "evaluator.reset()\n",
    "\n",
    "for name, local_model_ty in setups.items():\n",
    "    evaluator.reset()\n",
    "    fed = make_federation(rec=deepcopy(rec),\n",
    "                          data=df,\n",
    "                          local_model_ty=local_model_ty)\n",
    "    fed = simulate(fed, replay, [evaluator], full_history=True)\n",
    "    reports[name] = evaluator.report.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    " 'text.usetex': False,\n",
    " 'font.family': 'serif',\n",
    " 'text.latex.preamble': '\\\\usepackage{times} ',\n",
    " 'figure.figsize': (5.95, 1.785),\n",
    " 'figure.constrained_layout.use': True,\n",
    " 'figure.autolayout': False,\n",
    " 'font.size': 8,\n",
    " 'axes.labelsize': 8,\n",
    " 'legend.fontsize': 6,\n",
    " 'xtick.labelsize': 6,\n",
    " 'ytick.labelsize': 6,\n",
    " 'axes.titlesize': 8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    'baseline': 'Full model',\n",
    "    'hypothesis1': 'Rare local updates',\n",
    "    'hypothesis2': 'No local updates',\n",
    "    'item2item': 'SR(od)',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends = {}\n",
    "for name in ('baseline', 'hypothesis1', 'hypothesis2', 'item2item'):\n",
    "    report = reports[name].reset_index(level=[2])\n",
    "    trends[name] = report[report.metric == 'hr'][5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('data/dynamic-no-privacy.npz', **trends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "golden_ratio = 0.6180339887\n",
    "width = 6.91560069445\n",
    "height = width * golden_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mpl.rc_context(params):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 3), dpi=150)\n",
    "\n",
    "    ax = axes[0]\n",
    "    for name in ('baseline', 'hypothesis1', 'hypothesis2', 'item2item'):\n",
    "        ax.plot(trends[name], label=names[name])\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0.6, 0.9)\n",
    "    ax.set_xlabel('Cycle')\n",
    "    ax.set_ylabel('Hit Rate (HR@5)')\n",
    "\n",
    "    ax = axes[1]\n",
    "    for name in ('baseline', 'hypothesis1', 'hypothesis2', 'item2item'):\n",
    "        ax.plot((trends[name] - trends['baseline']).cumsum(), label=names[name])\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "    ax.set_ylim(-1.5, 0.1)\n",
    "    ax.set_xlabel('Cycle')\n",
    "    ax.set_ylabel(r'Cummulative $\\delta\\mathrm{HR@5}$')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
